{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling for Machine Learning ü§ñ\n",
    "\n",
    "As you go along you'll get to know about the two most important feature scaling techniquesüí• `StandardScaler`, also known as **Standardization**, and `MinMaxScaler`, also known as **Normalization**. And also about `MaxAbsScaler` and `RobustScaler`üî•.\n",
    "\n",
    "The first thing we need to do is to import some relevant libraries.\n",
    "\n",
    "## Import Libraries üì¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset üìÑ\n",
    "We'll be using the `Ames_Housing_Sales_RO.csv` Dataset. This dataset doesn't contain any outliers.\n",
    "\n",
    "The Ames housing dataset examines features of houses sold in Ames during the 2006‚Äì10 timeframe. The goal is to use the training data to predict the sale prices of the houses in the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>Alley</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>Street</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856.0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>8</td>\n",
       "      <td>856.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>920.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>6</td>\n",
       "      <td>920.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1145.0</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>9</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1694.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>1369.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>7</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>255.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>2005</td>\n",
       "      <td>2007</td>\n",
       "      <td>307000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>906.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>2008</td>\n",
       "      <td>129500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch Alley  BedroomAbvGr BldgType BsmtCond  \\\n",
       "0     856.0     854.0        0.0  None             3     1Fam       TA   \n",
       "1     920.0     866.0        0.0  None             3     1Fam       TA   \n",
       "2    1145.0    1053.0        0.0  None             4     1Fam       TA   \n",
       "3    1694.0       0.0        0.0  None             3     1Fam       TA   \n",
       "4    1040.0       0.0        0.0  None             3     1Fam       TA   \n",
       "\n",
       "  BsmtExposure  BsmtFinSF1  BsmtFinSF2  ... ScreenPorch Street  TotRmsAbvGrd  \\\n",
       "0           No       706.0         0.0  ...         0.0   Pave             8   \n",
       "1           Mn       486.0         0.0  ...         0.0   Pave             6   \n",
       "2           Av       655.0         0.0  ...         0.0   Pave             9   \n",
       "3           Av      1369.0         0.0  ...         0.0   Pave             7   \n",
       "4           No       906.0         0.0  ...         0.0   Pave             5   \n",
       "\n",
       "   TotalBsmtSF Utilities  WoodDeckSF YearBuilt YearRemodAdd YrSold SalePrice  \n",
       "0        856.0    AllPub         0.0      2003         2003   2008  208500.0  \n",
       "1        920.0    AllPub         0.0      2001         2002   2008  223500.0  \n",
       "2       1145.0    AllPub       192.0      2000         2000   2008  250000.0  \n",
       "3       1686.0    AllPub       255.0      2004         2005   2007  307000.0  \n",
       "4       1040.0    AllPub         0.0      1965         1965   2008  129500.0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/Ames_Housing_Sales_RO.csv')\n",
    "data.head() #this returns top 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 546 entries, 0 to 545\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   1stFlrSF       546 non-null    float64\n",
      " 1   2ndFlrSF       546 non-null    float64\n",
      " 2   3SsnPorch      546 non-null    float64\n",
      " 3   Alley          546 non-null    object \n",
      " 4   BedroomAbvGr   546 non-null    int64  \n",
      " 5   BldgType       546 non-null    object \n",
      " 6   BsmtCond       546 non-null    object \n",
      " 7   BsmtExposure   546 non-null    object \n",
      " 8   BsmtFinSF1     546 non-null    float64\n",
      " 9   BsmtFinSF2     546 non-null    float64\n",
      " 10  BsmtFinType1   546 non-null    object \n",
      " 11  BsmtFinType2   546 non-null    object \n",
      " 12  BsmtFullBath   546 non-null    int64  \n",
      " 13  BsmtHalfBath   546 non-null    int64  \n",
      " 14  BsmtQual       546 non-null    object \n",
      " 15  BsmtUnfSF      546 non-null    float64\n",
      " 16  CentralAir     546 non-null    object \n",
      " 17  Condition1     546 non-null    object \n",
      " 18  Condition2     546 non-null    object \n",
      " 19  Electrical     546 non-null    object \n",
      " 20  EnclosedPorch  546 non-null    float64\n",
      " 21  ExterCond      546 non-null    object \n",
      " 22  ExterQual      546 non-null    object \n",
      " 23  Exterior1st    546 non-null    object \n",
      " 24  Exterior2nd    546 non-null    object \n",
      " 25  Fence          546 non-null    object \n",
      " 26  FireplaceQu    546 non-null    object \n",
      " 27  Fireplaces     546 non-null    int64  \n",
      " 28  Foundation     546 non-null    object \n",
      " 29  FullBath       546 non-null    int64  \n",
      " 30  Functional     546 non-null    object \n",
      " 31  GarageArea     546 non-null    float64\n",
      " 32  GarageCars     546 non-null    int64  \n",
      " 33  GarageCond     546 non-null    object \n",
      " 34  GarageFinish   546 non-null    object \n",
      " 35  GarageQual     546 non-null    object \n",
      " 36  GarageType     546 non-null    object \n",
      " 37  GarageYrBlt    546 non-null    float64\n",
      " 38  GrLivArea      546 non-null    float64\n",
      " 39  HalfBath       546 non-null    int64  \n",
      " 40  Heating        546 non-null    object \n",
      " 41  HeatingQC      546 non-null    object \n",
      " 42  HouseStyle     546 non-null    object \n",
      " 43  KitchenAbvGr   546 non-null    int64  \n",
      " 44  KitchenQual    546 non-null    object \n",
      " 45  LandContour    546 non-null    object \n",
      " 46  LandSlope      546 non-null    object \n",
      " 47  LotArea        546 non-null    float64\n",
      " 48  LotConfig      546 non-null    object \n",
      " 49  LotFrontage    546 non-null    float64\n",
      " 50  LotShape       546 non-null    object \n",
      " 51  LowQualFinSF   546 non-null    float64\n",
      " 52  MSSubClass     546 non-null    int64  \n",
      " 53  MSZoning       546 non-null    object \n",
      " 54  MasVnrArea     546 non-null    float64\n",
      " 55  MasVnrType     546 non-null    object \n",
      " 56  MiscFeature    546 non-null    object \n",
      " 57  MiscVal        546 non-null    float64\n",
      " 58  MoSold         546 non-null    int64  \n",
      " 59  Neighborhood   546 non-null    object \n",
      " 60  OpenPorchSF    546 non-null    float64\n",
      " 61  OverallCond    546 non-null    int64  \n",
      " 62  OverallQual    546 non-null    int64  \n",
      " 63  PavedDrive     546 non-null    object \n",
      " 64  PoolArea       546 non-null    float64\n",
      " 65  PoolQC         546 non-null    object \n",
      " 66  RoofMatl       546 non-null    object \n",
      " 67  RoofStyle      546 non-null    object \n",
      " 68  SaleCondition  546 non-null    object \n",
      " 69  SaleType       546 non-null    object \n",
      " 70  ScreenPorch    546 non-null    float64\n",
      " 71  Street         546 non-null    object \n",
      " 72  TotRmsAbvGrd   546 non-null    int64  \n",
      " 73  TotalBsmtSF    546 non-null    float64\n",
      " 74  Utilities      546 non-null    object \n",
      " 75  WoodDeckSF     546 non-null    float64\n",
      " 76  YearBuilt      546 non-null    int64  \n",
      " 77  YearRemodAdd   546 non-null    int64  \n",
      " 78  YrSold         546 non-null    int64  \n",
      " 79  SalePrice      546 non-null    float64\n",
      "dtypes: float64(21), int64(16), object(43)\n",
      "memory usage: 341.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# examine each of the columns\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate features and target üññ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"SalePrice\"\n",
    "\n",
    "X = data.drop(target_col, axis=1)\n",
    "y = data[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping categorical variables\n",
    "X = X.drop(X.columns[X.dtypes == np.object], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and test splits ‚öîÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # splits train and test in 7:3 ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling ‚öñÔ∏è\n",
    "\n",
    "It is a good practice to fit the scaler on the training data and then use it to transform the testing data. This would avoid any data leakage during the model testing process. Also, the scaling of target values is generally not required.\n",
    "\n",
    "### Standard Scaler, also known as Standardization\n",
    "\n",
    "It is a scaling technique that standardized the data by subtracting it from its mean and then dividing it by the standard deviation.. The values are centered around the mean. It doesn't have a bounding range.\n",
    "\n",
    "Standardization can be useful where the data follows a Gaussian distribution i.e., Normally Distributed.\n",
    "\n",
    "##### Import the class containing the `StandardScaler` from `sklearn.preprocessing` and create an instance of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "SS = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit StandardScaler on X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset = X_train.copy() # copy because we'll use this set again\n",
    "X_train_ss = SS.fit_transform(trainingset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all the variables are on the same scale.\n",
    "##### Fit Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import linear regression and create an instance of it\n",
    "from sklearn.linear_model import LinearRegression\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train_ss, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting\n",
    "\n",
    "Before predicting, we need to transform the test-set as well according to how we transformed the train-set.\n",
    "\n",
    "We have to use the mean and standard deviation that was originally defined for the training set. That's why we use `SS.transform` on test-set instead of `SS.fit_fransform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = X_test.copy() # copy because we'll use this set again\n",
    "X_test_ss = SS.transform(testset) \n",
    "y_pred_train_ss = LR.predict(X_train_ss) # using train data\n",
    "y_pred_test_ss = LR.predict(X_test_ss) # using test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Squared Error (MSE)\n",
    " It is the simplest and most common loss function, it takes the difference between your model's predictions and the ground truth, squares it, and averages it out across the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for error values\n",
    "error_df = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the method mean_squared_error from the sklearn.metrics\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :  315636113.76629907\n",
      "Test :  300641635.0900279\n"
     ]
    }
   ],
   "source": [
    "mse_train_ss =  mean_squared_error(y_train, y_pred_train_ss)\n",
    "mse_test_ss =  mean_squared_error(y_test, y_pred_test_ss)\n",
    "print(\"Train : \", mse_train_ss)\n",
    "print(\"Test : \", mse_test_ss)\n",
    "\n",
    "error_df.append(pd.Series({'train': str(mse_train_ss),\n",
    "                           'test' : str(mse_test_ss)},\n",
    "                          name='standardscaling'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaler, also known as Normalization\n",
    "\n",
    "It is a scaling technique that converts variables to continuous variables in the 0-1 interval by mapping minimum values to 0 and maximum to 1.\n",
    "\n",
    "Normalization is good to use when you know that the distribution of your data does not follow a Gaussian distribution. It is sensitive to Outliers.\n",
    "\n",
    "This can be useful in algorithms that do not assume any distribution of the data like **K-Nearest Neighbors** and **Neural Networks**.\n",
    "\n",
    "##### Import the class containing the `MinMaxScaler` from `sklearn.preprocessing` and create an instance of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "MMS = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit MinMaxScaler on X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset = X_train.copy() # copy because we'll use this set again\n",
    "X_train_mms = MMS.fit_transform(trainingset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.fit(X_train_mms, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the test set\n",
    "testset = X_test.copy() # copy because we'll use this set again\n",
    "X_test_mms = MMS.transform(testset)\n",
    "\n",
    "# predicting\n",
    "y_pred_train_mms = LR.predict(X_train_mms) # using train data\n",
    "y_pred_test_mms = LR.predict(X_test_mms) # using test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :  315636113.7662993\n",
      "Test :  300641635.09002805\n"
     ]
    }
   ],
   "source": [
    "mse_train_mms =  mean_squared_error(y_train, y_pred_train_mms)\n",
    "mse_test_mms =  mean_squared_error(y_test, y_pred_test_mms)\n",
    "print(\"Train : \", mse_train_mms)\n",
    "print(\"Test : \", mse_test_mms)\n",
    "\n",
    "error_df.append(pd.Series({'train': str(mse_train_mms),\n",
    "                           'test' : str(mse_test_mms)},\n",
    "                          name='minmaxscaling'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Abs Scaler\n",
    "\n",
    "It is a scaling technique that scales variables by maximum absolute value. It is similar to Min Max Scaler, therefore, it is also sensitive to outliers.\n",
    "\n",
    "##### Import the class containing the `MaxAbsScaler` from `sklearn.preprocessing` and create an instance of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Scaler\n",
    "\n",
    "It is a scaling technique that is similar to Min-Max Scaler but instead maps the interquartile range, 75th percentile value minus the 25th percentile value, to 0-1.\n",
    "\n",
    "It is robust to outliers.\n",
    "\n",
    "##### Import the class containing the `RobustScaler` from `sklearn.preprocessing` and create an instance of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {'maxabsscaling': MaxAbsScaler(),\n",
    "            'robustscaling': RobustScaler()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over scalers and calculate errors\n",
    "for scaler_label, scaler in scalers.items():\n",
    "    trainingset = X_train.copy() # copy because we'll use this set again\n",
    "    # scale trainset\n",
    "    X_train_s = scaler.fit_transform(trainingset)\n",
    "    # fit regression\n",
    "    LR.fit(trainingset, y_train)\n",
    "    # transform the test set\n",
    "    testset = X_test.copy() # copy because we'll use this set again\n",
    "    X_test_s = scaler.transform(testset)\n",
    "    # predicting\n",
    "    y_pred_train_s = LR.predict(X_train_s) # using train data\n",
    "    y_pred_test_s = LR.predict(X_test_s) # using test data\n",
    "    error_df.append(pd.Series({'train': str(mean_squared_error(y_train, y_pred_train_s)),\n",
    "                                'test' : str(mean_squared_error(y_test, y_pred_test_s))},\n",
    "                                name=scaler_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standardscaling</th>\n",
       "      <th>minmaxscaling</th>\n",
       "      <th>maxabsscaling</th>\n",
       "      <th>robustscaling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>315636113.76629907</td>\n",
       "      <td>315636113.7662993</td>\n",
       "      <td>3349773986825.721</td>\n",
       "      <td>3353991317143.2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>300641635.0900279</td>\n",
       "      <td>300641635.09002805</td>\n",
       "      <td>3347205594248.1323</td>\n",
       "      <td>3349556724291.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          standardscaling       minmaxscaling       maxabsscaling  \\\n",
       "train  315636113.76629907   315636113.7662993   3349773986825.721   \n",
       "test    300641635.0900279  300641635.09002805  3347205594248.1323   \n",
       "\n",
       "            robustscaling  \n",
       "train  3353991317143.2114  \n",
       "test     3349556724291.42  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assemble the results\n",
    "error_df = pd.concat(error_df, axis=1)\n",
    "error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time in linear regression, the scaling won't affect the outcome. However, this is not the case with **Ridge** and **Lasso** Regression. And with distance-based algorithms like **KNN**, **K-means**, and **SVM**."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2f61642c73397aee4fb8f9fd49da4a6418d71ff277291f75e7c7e32695bb542"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
