{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuningüîß in Lasso‚û∞ and Ridge‚õ∞Ô∏è Regressions\n",
    "\n",
    "As you go along you'll learn to tune `alpha`, the hyperparameter of the lasso‚û∞, and ridge‚õ∞Ô∏è regression so that we can find the nice trade-off between bias and variance and get the best score.\n",
    "\n",
    "About `GridSearchCV` and `RandomSearchCV` function, which does all the steps of hyperparameter tuning for us. And also about `Pipeline` that let us chain together multiple operators.\n",
    "\n",
    "The first thing we need to do is to import some relevant libraries.\n",
    "\n",
    "## Import Libraries üì¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset üìÑ\n",
    "\n",
    "We'll be using Boston House Prices Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note we are loading a slightly different (\"cleaned\") pickle file\n",
    "boston = pickle.load(open('../datasets/boston_housing_clean.pickle', \"rb\" ))\n",
    "data = boston['dataframe']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Feature and Target Data ü§å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating X and y Variables\n",
    "X = data.drop('MEDV', axis=1)\n",
    "y = data.MEDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiating KFold Object\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(shuffle=True, random_state=72018, n_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression ‚û∞\n",
    "\n",
    "We'll tune the `alpha` hyperparameter for Lasso regression.\n",
    "\n",
    "First, we're going to generate an exponentially spaces range of alpha values using the NumPy `geomspace` function. And we are going to see which one of our different alpha values is going to lead to the highest score for our holdout set.\n",
    "\n",
    "> üí° Whenever you're doing lasso or ridge regression,¬†always have to scale your data, otherwise, the model will not work optimally.\n",
    "\n",
    "##### Generate a list of `alphas` for hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.e-09 1.e-08 1.e-07 1.e-06 1.e-05 1.e-04 1.e-03 1.e-02 1.e-01 1.e+00]\n"
     ]
    }
   ],
   "source": [
    "alphas = np.geomspace(1e-9, 1e0, num=10)\n",
    "print(alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create an instance of `PolynomialFeatures` and `StandardScaler`\n",
    "As we are going to add polynomial features and also scale our data. Doing so will increase the complexity of the model and then we can apply regularization so that we can find the nice trade-off between bias and variance and get the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "SS = StandardScaler()\n",
    "PF = PolynomialFeatures(degree=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's fit lasso regression for different `alpha` values and see which one of our `alpha` value lead to the highest score for our holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class containing lass\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also import the class containing `Pipeline` that let us chain together multiple operators on our data that both have a `fit` method.\n",
    "\n",
    "A pipeline contains a series of steps, where a step is (\"name of step\", actual_model). The \"name of step\" string is only used to help you identify which step you are on, and to allow you to specify parameters at that step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "scores = []\n",
    "for alpha in alphas:\n",
    "    las = Lasso(alpha=alpha, max_iter=10000)\n",
    "\n",
    "    estimator = Pipeline([\n",
    "        (\"make_higher_degree\", PF), # increases model complexity\n",
    "        (\"scaler\", SS), # scaling\n",
    "        (\"lasso_regression\", las),  # applying regularization\n",
    "    ])\n",
    "\n",
    "    predictions = cross_val_predict(estimator, X, y, cv = kf)\n",
    "    score = r2_score(y, predictions)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1e-09, 0.4121422683020509),\n",
       " (1e-08, 0.4121650350032843),\n",
       " (1e-07, 0.4123925099773915),\n",
       " (1e-06, 0.41465558882945774),\n",
       " (1e-05, 0.4339430589672577),\n",
       " (0.0001, 0.5324110399207135),\n",
       " (0.001, 0.7462275421476046),\n",
       " (0.01, 0.8590823497516458),\n",
       " (0.1, 0.8280423631185617),\n",
       " (1.0, 0.7328688516176427)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(alphas,scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2020148d4f0>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfnklEQVR4nO3deXhU5f338fc3k4U9LAlLNnYERMISAevaX9XiBriUCnS32lrtavsT2/6sl2310a5XW+2jPr9uiqJYDVgp2lat1goSSMIOjWExEyAhQAhL1rmfPxIxxAgTmJkzy+d1XShzcjLn4034XMdz5r6POecQEZHYl+R1ABERCQ0VuohInFChi4jECRW6iEicUKGLiMQJFbqISJxI9urAGRkZbtiwYV4dXkQkJq1Zs2afcy6zs695VujDhg2jqKjIq8OLiMQkM9v5YV/TJRcRkTihQhcRiRMqdBGROKFCFxGJEyp0EZE4oUIXEYkTKnQRCas9tfWUVR32OkZC8Oxz6CIS/+rqm7j+t//Gf/AYBUP7sWBGHldMGEK3FJ/X0eKSztBFJGx+/OJmdtce40sXj6DmSCPffLqUGff/gx+/uInyap21h5rO0EUkLF7dWsXi1e/y5YtHsvCKsSycOZa33qlh0apd/P7NHTz2xnbOHzWABdOHctn4QaT4dH55psyrR9AVFBQ4Tf0XiU+1R5u4/Jf/JL17Ci989QLSkk+8xFJVV8+SogqeXLUL/8FjZPZO45MFudw4LZecfj08Sh0bzGyNc66g06+p0EUk1L75dAkvlFby/FfO55yc9A/dryXgeH1bNYtW7eSVLVU44JIxmSyYPpSPjh2IL8kiFzpGnKzQdclFREJqxYY9PF/s5+sfG33SMgfwJRkfHTuQj44diP/gMZ5+exeLV7/LF/9URFZ6N26clscnz81lUJ9uEUof23SGLiIhU3O4gct/8TqD07tReNv5p3VdvKklwD8272XRql288Z99+JKMy8YNYsGMPM4fmUFSgp+16wxdRMLOOcf3CzdQV9/MkzdPOu2bnCm+JGZOGMLMCUPYse8IT63exZKiClZs3MPQAT2YPy2PG6bmMKBXWoj/C2KfztBFJCSWlvj5+uIS/nvmWXzlklEhfe+G5hZWbNjDolW7eHv7flJ9ScycMJgF0/OYNrw/Zolz1q4zdBEJq6pD9dy9dCOT8/pyy4UjQv7+ack+Zk/KZvakbP6zt45Fq3bx57UVLCutZNTAXiyYnsd1k3NI75ES8mPHEp2hi8gZcc5x0x+LeLNsH8u/fiEjM3tF5LjHGlt4YV0li1btovTdg3RLSeKaiVksmDGU/Jz0uD1r1xm6iITNkjUVvLKliruvHh+xMgfonupjbkEucwty2eCvZdGqXSwt8bNkTQVnZ/VhwfShzJqURa+0xKk5naGLyGnzHzzGx3/xOmdn9eGpm2d4/gmUuvomlpZU8sTKnWzZU0fPVB9zJmezYPpQxmf18TRbqOgMXURCLhBw3PnsOgLO8dNP5Hte5gC9u6XwqRlDWTA9j+J3D7Jo5S6eXVPBolW7mJzXl+9fNY6pQ/t7HTNstHiCiJyWRat28q+yfXzvqnHk9o+u6fpmxpS8fvxsbj6rvvsx/ufq8VQdauALfyhiZ80Rr+OFjQpdRLpsZ80R7lu+hQtHZzB/Wp7XcU6qb49UbrpgOE/dPAOALz2+hiMNzR6nCg8Vuoh0SUvA8Z0l60j2GQ/eMDFmPk2SN6AHv5k/mW176/jOs6V4df8wnFToItIlv39zO2/v2M8915zNkPTuXsfpkgtHZ7LwirEsX7+Hh197x+s4IadCF5GglVXV8eBLW7l03CCum5LtdZzTcvOFI5iVn8VPX97Kq1urvI4TUip0EQlKc0uAO54ppUeqj/uumxAzl1o6MjMeuH4i4wb34WtPFbN9X/zcJFWhi0hQHnm9nNKKWn40ZwIDe8f2crbdU3088umpJCcZt/ypiMNxcpNUhS4ip7Sp8hC//Ps2rpo4hKsnZnkdJyRy+/fgoflTKN93hG89XUIgEPs3SVXoInJSjc0B7lhSSnr3VH44e4LXcULqI6My+N6V43h5015+82qZ13HOWFCFbmYzzWyrmZWZ2cJOvp5nZq+aWbGZrTOzK0MfVUS88OtX/sPm3Ye4/7pz6N8z1es4Iff584dx3ZRsfv63bfx9016v45yRUxa6mfmAh4ArgPHAPDMb32G37wPPOOcmAzcCD4c6qIhEXum7B3n4tXe4fkoOl40f5HWcsDAz7rv2HM7JTuebT5dQVnXY60inLZgz9GlAmXOu3DnXCCwGZnfYxwHvrXyTDlSGLqKIeKG+qYU7lpSS2SuNu6/peA4XX7qltN4kTU1O4pbHizhU3+R1pNMSTKFnA++2e13Rtq29e4BPmVkFsBz4akjSiYhnfv63bZRVHebBGyaS3j3+HxyR1bc7Dy+Ywq6ao3xzcWzeJA3VTdF5wB+ccznAlcDjZvaB9zazW8ysyMyKqqurQ3RoEQm1oh37eeyNcuZPz+OiMZlex4mY6SMGcPc14/nHlip++fdtXsfpsmAK3Q/ktnud07atvZuAZwCcc28B3YCMjm/knHvUOVfgnCvIzEycHxKRWHK0sZk7lpSS0687371ynNdxIu7TM4YytyCHX71SxooNe7yO0yXBFPpqYLSZDTezVFpvei7rsM8u4GMAZjaO1kLXKbhIDHrgr1vYWXOUn9yQn1BP+3mPmXHv7Ank5/bljmdK2La3zutIQTtloTvnmoHbgZeAzbR+mmWjmd1rZrPadrsDuNnMSoGngM+5eFzKTCTOvVm2jz++tZMvnD+cGSMGeB3HM91SfDzyqal0T03mlj8VUXs0Nm6S6hF0IgK0Pr5t5i/fIC05ieVfv5BuKT6vI3muaMd+5j22kvNHZfC/nz0XXxQ8lelkj6DTTFERAeDHL25md+0xfjo3X2XepmBYf+6ZdTavba3mZy9v9TrOKSXeBTIR+YBXt1SxePW73HrJSKbk9fM6TlRZMH0oG/yHePi1dzg7K52rJg7xOtKH0hm6SII7eLSRO/+8jrMG9eYbl472Ok5UumfWeKYO7ce3l5Syefchr+N8KBW6SIK7Z9lG9h9p5Gdz80lL1qWWzqQl+/jtgin06Z7MLY8XcfBoo9eROqVCF0lgKzbsprCkktv/axQTstO9jhPVBvbpxm8/NZW9tQ189alimlsCXkf6ABW6SIKqOdzA957fwITsPtz20VFex4kJU/L68aM5E3jjP/v4yUvRd5NUN0VFEpBzju89v4G6+maemjuJFJ/O7YI199xc1vtreeT1csZn9WH2pOh5tqr+FEUS0LLSSlZs3MO3Lh/DmEG9vY4Tc/7n6vFMG9afO/+8jg3+Wq/jHKdCF0kwew/Vc/fSjUzJ68vNF47wOk5MSk1O4qEFU+jXI5UvPb6G/Uei4yapCl0kgTjnuOu59TQ0t/DTT+RHxczHWJXZO41HPj2V6sMN3LZobVTcJFWhiySQJUUVvLKlijtnjmVEZi+v48S8iTl9uf/ac3irvIb7lm/xOo5uiookiooDR7n3L5uYMaI/nz1vmNdx4sb1U3PYUFnL797czoTsPlw3JcezLDpDF0kAgYDjzj+vwznHT27IJ0mXWkLqu1eOY8aI/ix8bj3rKg56lkOFLpIAFq3ayZtlNXzvqvHk9u/hdZy4k+JL4qH5U8jslcaXHl9DdV2DJzlU6CJxbse+I9y3fAsXjclk3rTcU3+DnJYBvVpvkh442shtT66lyYObpCp0kTjWEnB859lSkn3GA9efg5kutYTThOx0Hrh+Im9v38+P/rIp4sfXTVGROPb7N7ezescBfj43nyHp3b2OkxBmT8pmg7+Wx97YztlZ6cw9N3L/V6QzdJE4VVZVx4MvbeWy8YO4dnL0TE9PBHfOHMsFozL4fuEGincdiNhxVegicerXr5SRlpzEfdfqUkukJfuS+PW8yQxKT+PLT6yhqq4+IsdVoYvEocMNzby0cQ+zJ2WR2TvN6zgJqV/PVB79dAGHjjVz6xNraWwO/01SFbpIHHp54x7qmwLMiaKVABPRuCF9+MknJrJm5wHueWFj2I+nm6IicaiwpJKcft2ZOlTPB/Xa1ROz2Fh5iN++9g4TstKZPz0vbMfSGbpInKmqq+df/6lmzqRsXTuPEt++/CwuHpPJD5ZtYM3O/WE7jgpdJM68ULqbgIM5k7O8jiJtfEnGr26cTFbf7nz5ibXsqQ3PTVIVukicWVriZ0J2H0YN1IMrokl6jxQe+0wBRxuaeXnTnrAcQ9fQReLIO9WHWVdRy/evGud1FOnEmEG9+ccdlzA4vVtY3l9n6CJxZGmxnySDWfm63BKtwlXmoEIXiRvOOQpLKjl/VAYD+4SvNCR6qdBF4sTaXQfZtf+oPnuewFToInGisNhPt5QkPj5hsNdRxCMqdJE40NQS4C/rKrls/GB6pemzDolKhS4SB17fVs2Bo03MmaSboYlMhS4SB54v9tOvRwoXjcn0Oop4SIUuEuPq6pv426a9XD0xixSf/konMv3pi8S4lzbupaE5wBw9xCLhBVXoZjbTzLaaWZmZLezk678ws5K2X9vM7GDIk4pIp5aW+Mnr34MpeX29jiIeO+XtcDPzAQ8BlwEVwGozW+acO/4EVOfcN9vt/1VgchiyikgHVYfqebNsH7d/dJRWVpSgztCnAWXOuXLnXCOwGJh9kv3nAU+FIpyInNyy0koCDmbrcosQXKFnA++2e13Rtu0DzGwoMBx45cyjicipFJb4mZiTzsjMXl5HkSgQ6puiNwLPOudaOvuimd1iZkVmVlRdXR3iQ4sklrKqOjb4D2mqvxwXTKH7gdx2r3PatnXmRk5yucU596hzrsA5V5CZqc/LipyJwuJKkgyuzh/idRSJEsEU+mpgtJkNN7NUWkt7WcedzGws0A94K7QRRaSj1pUV/VwwOpOBvbWyorQ6ZaE755qB24GXgM3AM865jWZ2r5nNarfrjcBi55wLT1QRec+anQeoOHBMU/3lBEGt4uOcWw4s77Dt7g6v7wldLBE5meeL/XRP8fHxs7WyorxPM0VFYkxjc4AX1+/msvGD6KmVFaUdFbpIjPnntmoOHm3iWn32XDpQoYvEmMISP/17pnLB6Ayvo0iUUaGLxJC6+ib+vmkv10wcopUV5QP0EyESQ1Zs2ENDc0BT/aVTKnSRGFJY4mfogB5Mzu3rdRSJQip0kRix91A9/36nhjmTsrWyonRKhS4SI5aVVOIcepCFfCgVukiMKCzxk5/bl+EZPb2OIlFKhS4SA7btrWNj5SFN9ZeTUqGLxIDCYj++JOPqiSp0+XAqdJEoFwg4lpZUcsGoDDJ7p3kdR6KYCl0kyhXtPID/4DFN9ZdTUqGLRLnCktaVFS8bP8jrKBLlVOgiUayxOcCL63bz8bO1sqKcmgpdJIq9trWK2mNNmuovQVGhi0SxwhI/A3qmcuEorawop6ZCF4lSh+qb+PvmKq7JzyJZKytKEPRTIhKlVqzfQ2NzQFP9JWgqdJEo9Xyxn+EZPcnPSfc6isQIFbpIFNpde4yV22uYPSlLKytK0FToIlHo+MqKk3S5RYKnQheJQoUllUzK7cswrawoXaBCF4kyW/fUsXn3IU31ly5ToYtEmcKS1pUVr5o4xOsoEmNU6CJRJBBwLC32c9HoDDJ6aWVF6RoVukgUWb1jP5W19frsuZwWFbpIFCks8dMjVSsryulRoYtEiYbmFl5ct5uZZw+mR6pWVpSuU6GLRIlXt1RzqL5ZKyvKaVOhi0SJwmI/Gb3SOH/kAK+jSIxSoYtEgdpjTbyypYpr8odoZUU5bfrJEYkCf12/m8aWgCYTyRlRoYtEgcISPyMyenJOtlZWlNOnQhfxWOXBY6ws38+cydlaWVHOiApdxGPLSisBmD0py+MkEuuCKnQzm2lmW82szMwWfsg+c81sk5ltNLMnQxtTJH4VFvuZkteXoQO0sqKcmVMWupn5gIeAK4DxwDwzG99hn9HAXcD5zrmzgW+EPqpI/Nm8+xBb9tRpqr+ERDBn6NOAMudcuXOuEVgMzO6wz83AQ865AwDOuarQxhSJT4UlfpKTjKvO0cqKcuaCKfRs4N12ryvatrU3BhhjZm+a2Uozm9nZG5nZLWZWZGZF1dXVp5dYJE4EAo5lJZVcPCaTAVpZUUIgVDdFk4HRwCXAPOAxM+vbcSfn3KPOuQLnXEFmZmaIDi0Sm1Zt38/u2npN9ZeQCabQ/UBuu9c5bdvaqwCWOeeanHPbgW20FryIfIjCYj89U31cNk4rK0poBFPoq4HRZjbczFKBG4FlHfYppPXsHDPLoPUSTHnoYorEl/qmFpZv2M3HJwyme6rP6zgSJ05Z6M65ZuB24CVgM/CMc26jmd1rZrPadnsJqDGzTcCrwHecczXhCi0S617dUkVdfbOm+ktIBbXosnNuObC8w7a72/3eAd9q+yUip1BY4iezdxofGZnhdRSJI5opKhJhtUebeHVLNbPys/Alaaq/hI4KXSTClm9oXVlxziRdbpHQUqGLRNjzxX5GZvZkQnYfr6NInFGhi0SQ/+Ax3t6+nzmTtLKihJ4KXSSClpa0TuGYrcstEgYqdJEIcc5RWOynYGg/8gb08DqOxCEVukiEbN5dx7a9hzXVX8JGhS4SIe+trHi1VlaUMFGhi0RAS9vKipeclUm/nqlex5E4pUIXiYBV5TXsOVSvB1lIWKnQRSKgsMRPr7RkLtXKihJGKnSRMKtvauGv6/cwc8JguqVoZUUJHxW6SJi9sqWKuoZmTfWXsFOhi4TZ88V+BvZO47yRA7yOInFOhS4SRgePNvLa1iqtrCgRoUIXCaMX1++mqcXp0y0SESp0kTAqLPYzemAvzs7SyooSfip0kTB5d/9RVu84wJzJWllRIkOFLhImy0orAZiVn+VxEkkUKnSRMHDO8Xyxn3OH9SO3v1ZWlMhQoYuEwcbKQ5RVHdbNUIkoFbpIGCwt8ZPiM67SyooSQSp0kRBrCTiWllRyyVkD6dtDKytK5KjQRULslS1VVNU1aKq/RJwKXSSE9tTWc9dz6xiZ2ZOPjRvodRxJMMleBxCJF43NAb6yaA3HGltYfMsMrawoEadCFwmR+5ZvZu2ugzw0fwqjBvb2Oo4kIF1yEQmBpSV+/vDvHdx0wXCumqhPtog3VOgiZ2jb3joW/nk95w7rx8IrxnodRxKYCl3kDNTVN/Hlx9fQMy2Zh+ZPIcWnv1LiHV1DFzlNzjm+s2QdO/cf5ckvTmdgn25eR5IEp9MJkdP02BvlrNi4h4UzxzJ9hJ5GJN5ToYuchpXlNTywYitXTBjMFy8c7nUcEUCFLtJlew/Vc/uTxQwd0IMHb5iotc4laugaukgXNLUEuG3RWo40NPPkzdPp3S3F60gixwV1hm5mM81sq5mVmdnCTr7+OTOrNrOStl9fDH1UEe/dv3wLRTsP8MANExkzSJOHJLqc8gzdzHzAQ8BlQAWw2syWOec2ddj1aefc7WHIKBIV/rKukt+9uZ3PfWSYnkIkUSmYM/RpQJlzrtw51wgsBmaHN5ZIdCmrquO/n13H1KH9+O6V47yOI9KpYAo9G3i33euKtm0dXW9m68zsWTPL7eyNzOwWMysys6Lq6urTiCsSeYcbmvnS42vokerjoflTSE3WZwkkOoXqJ/MFYJhzbiLwN+CPne3knHvUOVfgnCvIzMwM0aFFwsc5x53PrmP7viP8at5kBqdr8pBEr2AK3Q+0P+POadt2nHOuxjnX0Pby/wFTQxNPxFv/+6/tvLh+N/89cywfGZnhdRyRkwqm0FcDo81suJmlAjcCy9rvYGbtl5ebBWwOXUQRb7y9fT/3/3ULl48fxJcuGuF1HJFTOuWnXJxzzWZ2O/AS4AN+55zbaGb3AkXOuWXA18xsFtAM7Ac+F8bMImFXVVfPbU+uJa9/D346N1+ThyQmBDWxyDm3HFjeYdvd7X5/F3BXaKOJeKOpJcDtTxZTV9/E4zdNo48mD0mM0ExRkQ4eXLGFt7fv55efnMTYwX28jiMSNH3+SqSd5et389gb2/nMeUOZM7mzT+eKRC8VukibsqrDfGdJKZNy+/L9q8Z7HUeky1ToIsCRhmZufWINaSk+Hl6gyUMSm/RTKwnPOcfC59bzTvVhfj1vMll9u3sdSeS0qNAl4f3h3zt4obSSOy4/i/NHafKQxC4VuiS0oh37+fGLm7l03CBuvXik13FEzogKXRJWdV0Dtz25lux+3fnZ3HySkjR5SGKbCl0SUnNLgK8+tZbaY038dsFU0rtr8pDEPk0skoT0k5e3srJ8Pz/7RD7jszR5SOKDztAl4azYsIdH/lnOgul5XD81x+s4IiGjQpeEUl59mG8vKSU/J527r9HkIYkvKnRJGEcbm7n1ibWk+IyHPzWVtGSf15FEQkrX0CUhOOe467n1bKuq44+fn0a2Jg9JHNIZuiSEx1fuZGlJJd+6dAwXjdHjDyU+qdAl7q3ddYAf/mUT/zV2ILd9dJTXcUTCRoUucW3f4Qa+8sRaBqd34xdzJ2nykMQ1XUOXuNXcEuBrTxVz4Ggjf771I6T30OQhiW8qdIlbP//bNv79Tg0P3jCRCdnpXscRCTtdcpG49PLGPTz82jvMm5bL3IJcr+OIRIQKXeLOjn1HuOOZUs7JTucH15ztdRyRiFGhS1w51tjCl59Yg89nPLxgCt1SNHlIEocKXeLG4YZm7npuHVv31vHLT04it38PryOJRJRuikrMOtLQTNHOA7z1Tg1vldewwV9LS8DxjUtHc8lZA72OJxJxKnSJGccaWyjauZ+V5TW89U4N6ypqaQ44kpOM/Ny+3HrxSD4yagDnjRjgdVQRT6jQJWrVN7WwZueB4wVeWnGQphaHL8mYmJPOLReNYMaIARQM60ePVP0oi+hvgUSN+qYWincd5K3yGlaW11Cy6yCNLQGSDM7J6csXLhjOeSMGUDCsP73S9KMr0pH+VohnGppbKNl1kJXl+3mrfB9rdx2ksbm1wCdkp/O584e1FXg/enfTLE+RU1GhS8Q0NgcorTjIyrabmGt2HqChOYAZjB/Sh8/MGMp5I1vPwPWMT5GuU6FL2DS1BFhXUcvKtksoRTsOcKypBYBxQ/qwYPpQZozoz/ThA7TOikgIqNAlZJpbAqz317ZdQqmhaMd+jja2FvjYwb355Lm5zBgxgOnD+9OvZ6rHaUXijwo9ATjnaGgO0NAcoLE5QENzS9u/O9/W2T4Nne4ToKGphcaWAEcbW9jor+VIW4GPGdSLG6bmcN6IAUwfMYD+KnCRsIu5Qn9ly15eKN0d9P7OueD37WIW51q/571juLZ/OBzvHdZ1fN227b2jtX8P9yHv2/59jv++3fu2BNxJy7qxJdDF/7LOpSYnkXb8l4+05KR223xcOyWb80ZkMH1EfzJ6pYXkmCISvJgr9D21DazZeaBL32NdeKZBVx9/YGat32Pvf/972+z4Njshwwe+bu/vY+/v1OE92h2r3fdgkJaSRO9uyaQl+44XbGpbyR4v3JQkUn1JpKX4SPO1f5108u9r25bqS8K6MpAiEnExV+jzp+cxf3qe1zFERKJOUItzmdlMM9tqZmVmtvAk+11vZs7MCkIXUUREgnHKQjczH/AQcAUwHphnZuM72a838HVgVahDiojIqQVzhj4NKHPOlTvnGoHFwOxO9vsh8ABQH8J8IiISpGAKPRt4t93rirZtx5nZFCDXOffiyd7IzG4xsyIzK6quru5yWBER+XBn/IALM0sCfg7ccap9nXOPOucKnHMFmZmZZ3poERFpJ5hC9wPtn7Kb07btPb2BCcBrZrYDmAEs041REZHICqbQVwOjzWy4maUCNwLL3vuic67WOZfhnBvmnBsGrARmOeeKwpJYREQ6dcpCd841A7cDLwGbgWeccxvN7F4zmxXugCIiEhzrytT4kB7YrBrY6cnBQycD2Od1iCii8XifxuJEGo8Tncl4DHXOdXoT0rNCjwdmVuSc072CNhqP92ksTqTxOFG4xuOMP+UiIiLRQYUuIhInVOhn5lGvA0QZjcf7NBYn0nicKCzjoWvoIiJxQmfoIiJxQoUuIhInVOgiInFChR4mZpZnZoVm9ruTPRQkEZhZkpn92Mx+bWaf9TpPNDCznm0rj17tdRavmdkcM3vMzJ42s8u9zhNpbT8Lf2wbgwVn8l4q9E60lXCVmW3osD2oJze1OQd41jn3BWBy2MKGWYjGYjati7o10br8cswK0XgA3Ak8E56UkROK8XDOFTrnbga+DHwynHkjpYvjch2tXXEzcEbLqehTLp0ws4uAw8CfnHMT2rb5gG3AZbSW0mpgHuAD7u/wFl8AWoBnAQc87pz7fWTSh1aIxuILwAHn3CNm9qxz7oZI5Q+1EI1HPjAA6Absc879JTLpQy8U4+Gcq2r7vp8Bi5xzayMUP2y6OC6zgb8650rM7Enn3PzTPW7MPSQ6Epxzr5vZsA6bjz+5CcDMFgOznXP3Ax/432Yz+zbwg7b3ehaIyUIP0VhUAI1tL1vCGDfsQjQelwA9aX2k4zEzW+6cC4Qzd7iEaDwM+D+0llrMlzl0bVxoLfccoIQzvGqiQg9eZ09umn6S/VcA95jZfGBHGHN5oatj8RzwazO7EHg9nME80qXxcM59D8DMPkfrGXpMlvlJdPXn46vApUC6mY1yzv3fcIbz0IeNy6+A35jZVcALZ3IAFXqYOOc2ADF7aSGUnHNHgZu8zhFtnHN/8DpDNHDO/YrWUktIzrkjwOdD8V66KRq8Uz25KZFoLE6k8TiRxqNzYR8XFXrwTvrkpgSjsTiRxuNEGo/OhX1cVOidMLOngLeAs8yswsxu+rAnN3mZMxI0FifSeJxI49E5r8ZFH1sUEYkTOkMXEYkTKnQRkTihQhcRiRMqdBGROKFCFxGJEyp0EZE4oUIXEYkTKnQRkTihQhcRiRP/H1oz40KD27LZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(alphas, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `alpha` = 1e-09 is the most complex of the models.\n",
    "\n",
    "And, `alpha` = 1.0 is the least complex.\n",
    "\n",
    "So, looking at this graph we can say that at this `alpha` = 0.01 we¬†get our optimal value in regards to the hyperparameter¬†that will generalize well to new data coming in.\n",
    "\n",
    "Now that we've found the hyperparameter, we can train it on all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9351365368088853\n"
     ]
    }
   ],
   "source": [
    "best_estimator = Pipeline([\n",
    "        (\"make_higher_degree\", PolynomialFeatures(degree=3)), # increases model complexity\n",
    "        (\"scaler\", SS), # scaling\n",
    "        (\"lasso_regression\", Lasso(alpha=0.01, max_iter=100000)),  # applying regularization\n",
    "    ])\n",
    "\n",
    "best_estimator.fit(X, y)\n",
    "print(best_estimator.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression ‚õ∞Ô∏è\n",
    "\n",
    "Again, we'll be doing the same thing, but with Ridge regression.\n",
    "Our goal is again the same to find the optimal hyperparameters so that it generalizes well to new data.\n",
    "\n",
    "##### Generate a list of `alphas` for hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1        0.13949508 0.19458877 0.27144176 0.3786479  0.52819519\n",
      " 0.7368063  1.02780853 1.43374233 2.        ]\n"
     ]
    }
   ],
   "source": [
    "alphas = np.geomspace(0.1, 2, 10)\n",
    "print(alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's fit ridge regression for different `alpha` values and see which one of our `alpha` value lead to the highest score for our holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ridge\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "PF = PolynomialFeatures(degree=2)\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha, max_iter=10000)\n",
    "\n",
    "    estimator = Pipeline([\n",
    "        (\"polynomial_features\", PF),\n",
    "        (\"scaler\", SS),\n",
    "        (\"ridge_regression\", ridge)\n",
    "    ])\n",
    "\n",
    "    predictions = cross_val_predict(estimator, X, y, cv = kf)\n",
    "    score = r2_score(y, predictions)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1, 0.8538653466410988),\n",
       " (0.13949507939624212, 0.8560903220965068),\n",
       " (0.19458877175763892, 0.8579015123237039),\n",
       " (0.2714417616594907, 0.8593091413433599),\n",
       " (0.3786479009414648, 0.8603451339912741),\n",
       " (0.5281951900505005, 0.8610264794897184),\n",
       " (0.7368062997280774, 0.8613351147459642),\n",
       " (1.0278085328021955, 0.8612193278557753),\n",
       " (1.4337423288737734, 0.8606037281787884),\n",
       " (2.0, 0.8593902395694217)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(alphas,scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x202012e1790>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(alphas, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, looking at this graph we can say that at this `alpha` = `0.7368062997280774` we¬†get our optimal value in regards to the hyperparameter¬†that will generalize well to new data coming in.\n",
    "\n",
    "Now that we've found the hyperparameter, we can train it on all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9137010430449919\n"
     ]
    }
   ],
   "source": [
    "best_estimator = Pipeline([\n",
    "        (\"make_higher_degree\", PolynomialFeatures(degree=2)), # increases model complexity\n",
    "        (\"scaler\", SS), # scaling\n",
    "        (\"ridge_regression\", Ridge(alpha=0.7368062997280774, max_iter=100000)),  # applying regularization\n",
    "    ])\n",
    "\n",
    "best_estimator.fit(X, y)\n",
    "print(best_estimator.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Both Lasso and Ridge with proper hyperparameter tuning give better results than plain Linear Regression!\n",
    "\n",
    "## Grid Search CV üèÅ\n",
    "\n",
    "`GridSearchCV` is a function that we can import from `sklearn.model_selection` that does all these steps for us.\n",
    "\n",
    "GridSearchCV takes a `model` (or `pipeline`) and a dictionary of parameters to scan over. It finds the hyperparameter set that has the best out-of-sample score on all the parameters, and calls that it's \"best estimator\". It then retrains on all data with the \"best\" hyper-parameters.\n",
    "\n",
    "### Tuning hyperparameters for Lasso Regression ‚û∞\n",
    "We'll be doing all of this that we did in just one step using Grid Search CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Same estimator as before\n",
    "estimator = Pipeline([\n",
    "        (\"polynomial_features\",  PolynomialFeatures()), # increases model complexity\n",
    "        (\"scaler\", StandardScaler()), # scaling\n",
    "        (\"lasso_regression\", Lasso()),  # applying regularization\n",
    "    ])\n",
    "\n",
    "params = {\n",
    "    'polynomial_features__degree': [1, 2, 3], # tune degree for polynomial features\n",
    "    'lasso_regression__alpha': np.geomspace(1e-9, 1e0, num=10) # tune alpha value for lasso\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator, params, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=72018, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('polynomial_features',\n",
       "                                        PolynomialFeatures()),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('lasso_regression', Lasso())]),\n",
       "             param_grid={'lasso_regression__alpha': array([1.e-09, 1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02,\n",
       "       1.e-01, 1.e+00]),\n",
       "                         'polynomial_features__degree': [1, 2, 3]})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8589963567948978 {'lasso_regression__alpha': 0.01, 'polynomial_features__degree': 2}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_, grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best score we're getting is `0.85` for the `degree` of `2` and an `alpha` value of `0.01`.\n",
    "\n",
    "We can then actually use that `grid` in order to predict the x-values, which is something we were not able to do that with `cross_val_predicts`, the reason that with grid search, it's going to test against all of the different holdout sets, and then once it's tested against all of the different holdout sets and it finds the best hyper-parameters that will fit for generalization for data-sets that we've never seen. It's then going to use those hyper-parameters to learn the parameters on the entire data-set because the more data that you have, the better you're going to be able to predict, and the idea is that you are now able to use this to predict as new data comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9047578542960124\n"
     ]
    }
   ],
   "source": [
    "y_predict = grid.predict(X)\n",
    "print(r2_score(y, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Similarly, we can tune for Ridge Regression too.**\n",
    "\n",
    "## Random Search CV üèÅ\n",
    "\n",
    "The only thing that is different here is it moves within the grid in a random fashion to find the best set of hyperparameters. This approach reduces unnecessary computation.\n",
    "\n",
    "### Tuning hyperparameters for Ridge Regression ‚õ∞Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Same estimator as before\n",
    "estimator = Pipeline([\n",
    "        (\"polynomial_features\",  PolynomialFeatures()), # increases model complexity\n",
    "        (\"scaler\", StandardScaler()), # scaling\n",
    "        (\"ridge_regression\", Ridge()),  # applying regularization\n",
    "    ])\n",
    "\n",
    "params = {\n",
    "    'polynomial_features__degree': [1, 2, 3], # tune degree for polynomial features\n",
    "    'ridge_regression__alpha': np.geomspace(0.1, 2, 10) # tune alpha value for ridge\n",
    "}\n",
    "\n",
    "rand = RandomizedSearchCV(estimator, params, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=3, random_state=72018, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('polynomial_features',\n",
       "                                              PolynomialFeatures()),\n",
       "                                             ('scaler', StandardScaler()),\n",
       "                                             ('ridge_regression', Ridge())]),\n",
       "                   param_distributions={'polynomial_features__degree': [1, 2,\n",
       "                                                                        3],\n",
       "                                        'ridge_regression__alpha': array([0.1       , 0.13949508, 0.19458877, 0.27144176, 0.3786479 ,\n",
       "       0.52819519, 0.7368063 , 1.02780853, 1.43374233, 2.        ])})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8614921774272938 {'ridge_regression__alpha': 0.7368062997280774, 'polynomial_features__degree': 2}\n"
     ]
    }
   ],
   "source": [
    "print(rand.best_score_, rand.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best score we're getting is `0.86` for the `degree` of `2` and an `alpha` value of `0.7368062997280774`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9137010430449919\n"
     ]
    }
   ],
   "source": [
    "y_predict = rand.predict(X)\n",
    "print(r2_score(y, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Similarly, we can tune for Lasso Regression too.**\n",
    "\n",
    "There is also\n",
    "- a `LassoCV` function that uses an L1 regularization function and cross-validation. L1 regularization will selectively shrink some coefficients, effectively performing feature elimination.\n",
    "- a `RidgeCV` function that uses an L2 regularization function and cross-validation. L2 regularization reduces the magnitude of the coefficients.\n",
    "- an `ElasticNetCV`, which is a combination of L2 and L1 regularization, with cross-validation. **ElasticNet** is similar to what we saw with the **Ridge**, and with **Lasso**, just with an extra hyperparameter of the `l1_ratio`."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2f61642c73397aee4fb8f9fd49da4a6418d71ff277291f75e7c7e32695bb542"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
